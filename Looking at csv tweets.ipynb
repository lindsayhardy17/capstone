{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will be finishing the process of cleaning the city and the state columns that we created with the CSV files.\n",
    "\n",
    "We first import the files that we will be combining together and put them into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (0,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (4,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('tweets-carmen.csv') \n",
    "df2 = pd.read_csv('tweets2-carmen.csv') \n",
    "df3 = pd.read_csv('tweets3-carmen.csv')\n",
    "df4 = pd.read_csv('tweets4-carmen.csv')  \n",
    "df5 = pd.read_csv('tweets5-carmen.csv') \n",
    "df6 = pd.read_csv('tweets6-carmen.csv') \n",
    "df7 = pd.read_csv('tweets7-carmen.csv') \n",
    "df8 = pd.read_csv('tweets8-carmen.csv') \n",
    "df9 = pd.read_csv('tweets9-carmen.csv') \n",
    "\n",
    "data = [df1,df2, df3, df4, df5,df6,df7,df8,df9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make sure that no values are in the location data that are not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = pd.DataFrame()\n",
    "for x in range(len(data)):\n",
    "    data[x]['state'] = data[x]['state'].str.replace('\\d+', 'no')\n",
    "    data[x]['state'] = data[x]['state'].str.replace('.', '')\n",
    "    data[x]['state'] = data[x]['state'].str.replace('-', ' ')\n",
    "    data[x]['state'] = data[x]['state'].str.replace(\"'\", ' ')\n",
    "    data[x]['state'] = data[x]['state'].replace(np.nan, 'no')\n",
    "    long = pd.concat([data[x],long])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency we change the state names to uppercase and observe the different unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PENNSYLVANIA', ' USA', 'NO', 'CALIFORNIA', 'NORTH CAROLINA',\n",
       "       'WASHINGTON', 'ARIZONA', ' TN', 'GEORGIA', ' GA', ' IL', 'FLORIDA',\n",
       "       'ILLINOIS', 'SOUTH CAROLINA', 'UTAH', ' CA', ' PA', 'NEW JERSEY',\n",
       "       'NEW YORK', ' NY', ' PENNSYLVANIA', 'MARYLAND', 'DELAWARE',\n",
       "       'COLORADO', ' DC ', 'DISTRICT OF COLUMBIA', 'KANSAS', 'WISCONSIN',\n",
       "       'IOWA', 'ENGLAND', 'LAGOS', 'NEVADA', 'NEW MEXICO', 'LOUISIANA',\n",
       "       'TENNESSEE', ' MD', ' PA NO BUCKS COUNTY', ' RM NO', 'INDIANA',\n",
       "       ' PENNSYLVANIA ', ' NJ', 'MASSACHUSETTS', 'INCHEON', 'TEXAS',\n",
       "       'CONNECTICUT', 'VIRGINIA', 'SAN SALVADOR', 'PIEDMONT',\n",
       "       ' BUCKS COUNTY', 'LATIUM', 'LOMBARDY', 'ONTARIO', 'TATARSTAN',\n",
       "       'TSENTRAL NIY FEDERAL NIY OKRUG', ' CALIFORNIA', 'BAJA CALIFORNIA',\n",
       "       'MICHIGAN', ' TOKYO', 'DISTRITO FEDERAL', 'GENEVA', 'KENTUCKY',\n",
       "       'NAIROBI', ' WA', 'OREGON', 'BALI', ' PR',\n",
       "       'NATIONAL CAPITAL REGION', 'MINNESOTA', ' NEW YORK ', 'ARKANSAS',\n",
       "       ' CALIF', 'ALABAMA', ' FL', ' CANADA', 'ZURICH', ' TX',\n",
       "       'PUERTO RICO', 'WESTERN AUSTRALIA', ' NONO', ' JAPAN', ' CAMPECHE',\n",
       "       'BRITISH COLUMBIA', 'SOUTH AUSTRALIA', ' MA (USA)', ' MN', ' OH',\n",
       "       'OHIO', ' CA NO', ' WISCONSIN', ' TEXAS', 'INDIA',\n",
       "       'NORTHERN IRELAND', ' CA & DC (CA NO)', 'CENTRAL SINGAPORE',\n",
       "       'QUEBEC', 'SOUTH DAKOTA', 'MISSOURI', 'NEBRASKA', 'LOWER SAXONY',\n",
       "       'ALBERTA', ' USA ', 'NEW SOUTH WALES', 'GAUTENG', ' FL NO',\n",
       "       ' ALBERTA', ' QUÉBEC', 'RIO DE JANEIRO', 'WALES', ' ILLINOIS',\n",
       "       ' ILL', ' FRANCE', 'HAWAII', 'CANADA', ' TENNESSEE USA', 'MAINE',\n",
       "       'ALASKA', ' HAWAII', ' CO', ' MT', ' SD', ' AR', ' WASHINGTON',\n",
       "       ' DC', 'BERLIN', 'NONO', 'MAZOWIECKIE', 'ÎLE DE FRANCE',\n",
       "       'TAMIL NADU', 'VICTORIA', 'ZACATECAS', 'RHONE ALPES',\n",
       "       'ILE DE FRANCE', 'BRUSSELS CAPITAL REGION', 'SCOTLAND', 'UTRECHT',\n",
       "       'COMUNIDAD DE MADRID', 'CATALONIA',\n",
       "       'AUTONOMOUS CITY OF BUENOS AIRES', 'SAO PAULO', 'TOKYO PREFECTURE',\n",
       "       'BALEARIC ISLANDS', 'BAVARIA', 'PROVENCE ALPES CÔTE D AZUR',\n",
       "       'QUEENSLAND', ' VIRGINIA', ' ONTARIO', 'HONG KONG ISLAND',\n",
       "       'DI YOGYAKARTA', ' GERMANY', ' GEORGIA', 'DC', 'VERMONT',\n",
       "       'BADEN WÜRTTEMBERG', ' NEW MEXICO', 'EAST COAST', ' IRELAND',\n",
       "       'FEDERAL CAPITAL TERRITORY', 'CENTRALNA SRBIJA',\n",
       "       'SEVERO ZAPADNIY FED OKRUG', ' NC', ' UTAH', ' MA', ' IOWA',\n",
       "       'CALABARZON', 'IDAHO'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long['state'] = long['state'].apply(lambda x: x.upper())\n",
    "long['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a list of each state that we will be doing analysis on, change all of the state names that are unique to one specific name, and filter out the rows that tweets that are not from these states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['NEW YORK', 'DC', 'WASHINGTON', 'OREGON','CALIFORNIA','MASSACHUSETTS','ILLINOIS',\n",
    "'PENNSYLVANIA','TEXAS','UTAH','MICHIGAN','ARIZONA','CALIFORNIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['PENNSYLVANIA', ' PENNSYLVANIA', 'PA', ' PA'], 'PENNSYLVANIA'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['CALIFORNIA', ' CALIFORNIA', 'CA', ' CA'], 'CALIFORNIA'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['WASHINGTON', ' WASHINGTON', 'WA', ' WA'], 'WASHINGTON'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['ILLINOIS', ' ILLINOIS', 'IL', ' IL', ' ILL', 'IL'], 'ILLINOIS'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['TEXAS', ' TEXAS', 'TX', ' TX'], 'TEXAS'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['ARIZONA', ' ARIZONA', 'AZ', ' AZ'], 'ARIZONA'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['NEW YORK', ' NEW YORK', 'NY', ' NY'], 'NEW YORK'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['UTAH', ' UTAH', 'UT', ' UT'], 'UTAH'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['MICHIGAN', ' MICHIGAN', 'MI', ' MI'], 'MICHIGAN'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['OREGON', ' OREGON', 'OR', ' OR'], 'OREGON'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['MASSACHUSETS', ' MASSACHUSETS', 'MA', ' MA'], 'MASSACHUSETS'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['DC', ' DC', 'D.C.', ' D.C.','DISTRICT OF COLUMBIA', ' DISTRICT OF COLUMBIA'], 'DC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_correct_states = long[long['state'].isin(locations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we do a similar analysis on the cities that we did for the states, we make each name upper case, look at the unique values, change different values to correspond with the correct location and then filter that data and create a new final dataframe called only_cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-80d2ef9a1a2c>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_correct_states['city'] = only_correct_states['city'].apply(lambda x: x.upper())\n"
     ]
    }
   ],
   "source": [
    "only_correct_states['city'] = only_correct_states['city'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_correct_states['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['PORTLAND'], 'PORTLAND'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['AUSTIN'], 'AUSTIN'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['SEATTLE'], 'SEATTLE'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['BOSTON', 'CAMBRIDGE', 'EAST BOSTON'], 'BOSTON'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['GLENDALE','PHOENIX', 'SCOTTSDALE', 'TEMPE','MESA'], 'PHOENIX'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['CHICAGO', 'DED PLAINES'], 'CHICAGO'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['PHILADELPHIA','MOSTLY PHILADELPHIA','PHILA.','UPPER DARBY'], 'PHILADELPHIA'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['BROOKLYN', 'MANHATTAN','NEW YORK', 'BRONX', 'ASTORIA','Queens', 'Staten Island'], 'NEW YORK'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['D.C.', 'WASHINGTON','ADAMS MORGAN'], 'DC'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['SALT LAKE CITY'], 'SALT LAKE CITY'))\n",
    "only_correct_states = only_correct_states.replace(dict.fromkeys(['OAKLAND','SOUTH SAN FRANCISCO','STANFORD','REDWOOD CITY','EAST PALO ALTO',\n",
    "                        'LOS ALTOS','DALY CITY','MENLO PARK','AMERICAN CANYON','WALNUT CREEK','BERKELEY',\n",
    "                         'PALO ALTO'], 'SAN FRANCISCO'))\n",
    "only_correct_states.replace(dict.fromkeys(['LOS ANGELES','BEVERLY HILLS','BEL AIR','EL SEGUNDO','CULVER CITY','SANTA MONICA','HERMOSA BEACH',\n",
    "                        'SHERMAN OAKS','TEMPLE', 'HOLLYWOOD', 'WEST HOLLYWOOD','SANTA MONICA', 'BEVERLY HILLS', 'VENICE'], 'LOS ANGELES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['PORTLAND','AUSTIN','SEATTLE','BOSTON','PHOENIX','CHICAGO','PHILADELPHIA','NEW YORK','DC',\n",
    "        'SALT LAKE CITY','SAN FRANCISCO', 'SALT LAKE CITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_cities = only_correct_states[only_correct_states['city'].isin(cities)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
