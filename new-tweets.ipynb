{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, upload, and create functions\n",
    "In this file we walk through the steps to forming the tweets from out json files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing carmen.egg-info/PKG-INFO\n",
      "writing dependency_links to carmen.egg-info/dependency_links.txt\n",
      "writing requirements to carmen.egg-info/requires.txt\n",
      "writing top-level names to carmen.egg-info/top_level.txt\n",
      "reading manifest file 'carmen.egg-info/SOURCES.txt'\n",
      "writing manifest file 'carmen.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/carmen\n",
      "copying build/lib/carmen/__init__.py -> build/bdist.linux-x86_64/egg/carmen\n",
      "copying build/lib/carmen/names.py -> build/bdist.linux-x86_64/egg/carmen\n",
      "creating build/bdist.linux-x86_64/egg/carmen/resolvers\n",
      "copying build/lib/carmen/resolvers/place.py -> build/bdist.linux-x86_64/egg/carmen/resolvers\n",
      "copying build/lib/carmen/resolvers/profile.py -> build/bdist.linux-x86_64/egg/carmen/resolvers\n",
      "copying build/lib/carmen/resolvers/geocode.py -> build/bdist.linux-x86_64/egg/carmen/resolvers\n",
      "copying build/lib/carmen/resolvers/__init__.py -> build/bdist.linux-x86_64/egg/carmen/resolvers\n",
      "copying build/lib/carmen/location.py -> build/bdist.linux-x86_64/egg/carmen\n",
      "copying build/lib/carmen/cli.py -> build/bdist.linux-x86_64/egg/carmen\n",
      "copying build/lib/carmen/resolver.py -> build/bdist.linux-x86_64/egg/carmen\n",
      "creating build/bdist.linux-x86_64/egg/carmen/data\n",
      "copying build/lib/carmen/data/locations.json -> build/bdist.linux-x86_64/egg/carmen/data\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/names.py to names.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/resolvers/place.py to place.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/resolvers/profile.py to profile.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/resolvers/geocode.py to geocode.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/resolvers/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/location.py to location.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/cli.py to cli.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/carmen/resolver.py to resolver.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying carmen.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying carmen.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying carmen.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying carmen.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying carmen.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying carmen.egg-info/zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "creating 'dist/carmen-0.0.4-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing carmen-0.0.4-py3.8.egg\n",
      "Copying carmen-0.0.4-py3.8.egg to /opt/conda/lib/python3.8/site-packages\n",
      "Adding carmen 0.0.4 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.8/site-packages/carmen-0.0.4-py3.8.egg\n",
      "Processing dependencies for carmen==0.0.4\n",
      "Searching for geopy\n",
      "Reading https://pypi.org/simple/geopy/\n",
      "Downloading https://files.pythonhosted.org/packages/07/e1/9c72de674d5c2b8fcb0738a5ceeb5424941fefa080bfe4e240d0bacb5a38/geopy-2.0.0-py3-none-any.whl#sha256=fdc596bab67d9f4828f43bf9e97c4e0a1d1518b7c2357485cef0e1c3cf470220\n",
      "Best match: geopy 2.0.0\n",
      "Processing geopy-2.0.0-py3-none-any.whl\n",
      "Installing geopy-2.0.0-py3-none-any.whl to /opt/conda/lib/python3.8/site-packages\n",
      "Adding geopy 2.0.0 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.8/site-packages/geopy-2.0.0-py3.8.egg\n",
      "Searching for geographiclib<2,>=1.49\n",
      "Reading https://pypi.org/simple/geographiclib/\n",
      "Downloading https://files.pythonhosted.org/packages/8b/62/26ec95a98ba64299163199e95ad1b0e34ad3f4e176e221c40245f211e425/geographiclib-1.50-py3-none-any.whl#sha256=51cfa698e7183792bce27d8fb63ac8e83689cd8170a730bf35e1a5c5bf8849b9\n",
      "Best match: geographiclib 1.50\n",
      "Processing geographiclib-1.50-py3-none-any.whl\n",
      "Installing geographiclib-1.50-py3-none-any.whl to /opt/conda/lib/python3.8/site-packages\n",
      "Adding geographiclib 1.50 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.8/site-packages/geographiclib-1.50-py3.8.egg\n",
      "Finished processing dependencies for carmen==0.0.4\n"
     ]
    }
   ],
   "source": [
    "#In order to run Carmen, which is location application that we use to look at the location elements of the tweet that \n",
    "#are not readily apprent in the json. To use Carmen we have to first import this file.\n",
    "import sys\n",
    "!python setup.py install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8eecc8011dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcarmen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarmen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/capstone/carmen/resolver.py\u001b[0m in \u001b[0;36mget_resolver\u001b[0;34m(order, options, modules)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpkgutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__path__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mfull_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'profile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_check_name_wrapper\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_module_shim\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/notebooks/capstone/carmen/resolvers/geocode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgeopy_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "#import numpy and then import carmen\n",
    "import numpy as np\n",
    "import carmen\n",
    "#these are two commands that are needed to start carmen\n",
    "resolver = carmen.get_resolver()\n",
    "resolver.load_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to select the specific elements from the JSON that we need, as well as using Carmen in this function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tweets(tweets):\n",
    "    \"\"\" Flattens out tweet dictionaries so relevant JSON is \n",
    "        in a top-level dictionary. \"\"\"\n",
    "    \n",
    "    tweets_list = []\n",
    "    # Iterate through each tweet\n",
    "    for tweet_obj in tweets:\n",
    "        tweet_obj = json.loads(tweet_obj)\n",
    "        ''' User info'''\n",
    "        # Store the user screen name in 'user-screen_name'\n",
    "        tweet_obj['user-screen_name'] = tweet_obj['user']['screen_name']\n",
    "        \n",
    "        # Store the user location\n",
    "        tweet_obj['user-location'] = tweet_obj['user']['location']\n",
    "        \n",
    "        # Store number of retweets\n",
    "        tweet_obj['retweet_number'] = tweet_obj['retweet_count']\n",
    "        \n",
    "        # Store number of favorites\n",
    "        tweet_obj['favorite_number'] = tweet_obj['favorite_count']\n",
    "        \n",
    "        # Store hashtags\n",
    "        if len(tweet_obj['entities']['hashtags']) != 0:\n",
    "            tweet_obj['hashtags'] = []\n",
    "            for x in range(len(tweet_obj['entities']['hashtags'])):\n",
    "                tweet_obj['hashtags'].append(tweet_obj['entities']['hashtags'][x]['text']) \n",
    "        if len(tweet_obj['entities']['hashtags']) == 0:\n",
    "            tweet_obj['hashtags'] = 'None'\n",
    "        \n",
    "        # Store data\n",
    "        tweet_obj['date'] = tweet_obj['created_at']\n",
    "        \n",
    "        #new location\n",
    "        tweet_obj['location1'] = resolver.resolve_tweet(tweet_obj)\n",
    "    \n",
    "        ''' Text info'''\n",
    "        # Check if this is a 140+ character tweet\n",
    "        if 'extended_tweet' in tweet_obj:\n",
    "            # Store the extended tweet text in 'extended_tweet-full_text'\n",
    "            tweet_obj['extended_tweet-full_text'] = \\\n",
    "                                    tweet_obj['extended_tweet']['full_text']\n",
    "        if 'quoted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in \n",
    "            #'retweeted_status-user-screen_name'\n",
    "            tweet_obj['quoted_status-user-screen_name'] = \\\n",
    "                            tweet_obj['quoted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['quoted_status-text'] = \\\n",
    "                                            tweet_obj['quoted_status']['text']\n",
    "    \n",
    "            if 'extended_tweet' in tweet_obj['quoted_status']:\n",
    "                # Store the extended retweet text in \n",
    "                #'retweeted_status-extended_tweet-full_text'\n",
    "                tweet_obj['quoted_status-extended_tweet-full_text'] = \\\n",
    "                    tweet_obj['quoted_status']['extended_tweet']['full_text']\n",
    "        \n",
    "        ''' Place info'''\n",
    "        if 'place' in tweet_obj:\n",
    "            # Store the country code in 'place-country_code'\n",
    "            try:\n",
    "                tweet_obj['place-country'] = \\\n",
    "                                            tweet_obj['place']['country']\n",
    "                \n",
    "                tweet_obj['place-country_code'] = \\\n",
    "                                            tweet_obj['place']['country_code']\n",
    "                \n",
    "                tweet_obj['location-coordinates'] = \\\n",
    "                            tweet_obj['place']['bounding_box']['coordinates']\n",
    "            except: pass\n",
    "        \n",
    "        tweets_list.append(tweet_obj)\n",
    "        \n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json so that we can open the json file\n",
    "import json\n",
    "f = open('tweets.json')\n",
    "tweets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# flatten tweets\n",
    "tweets1 = flatten_tweets(tweets)\n",
    "\n",
    "#here we create a list of the columns that we created above and designate these as the ones that we want in our datframe\n",
    "columns = ['text', 'lang', 'user-location', 'place-country', \n",
    "           'place-country_code', 'location-coordinates', \n",
    "           'user-screen_name', 'retweet_number','hashtags','date', 'location1']\n",
    "# Create a DataFrame from `tweets`\n",
    "df_tweets = pd.DataFrame(tweets1, columns=columns)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the dataframe\n",
    "After we create this dataframe it is time to start parsing the locations so we can determine exactly where the tweets are from which will help us in the sorting process.\n",
    "\n",
    "The first step is to sort through what Carmen created, we labeled this column as location1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carmen when it doesn't find a location for a value it labels it as None, we tried to sort out the values\n",
    "#using the original keyword none, but for some reason this didn't work, so we instead turned to just using the \n",
    "#designated type for None which we've created a variable for here\n",
    "none = type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-cbd001856326>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  use['city'] = use.apply(lambda row: city(row['location2']),axis=1)\n"
     ]
    }
   ],
   "source": [
    "#after creating that designated None value we can now create a function to find the city name if there is one\n",
    "def city(place):\n",
    "    #if there is some information about the place continue\n",
    "    if type(place) != none:\n",
    "        #if there is a city value return the city\n",
    "        if place[1].city != '':\n",
    "            return place[1].city\n",
    "        #else return no\n",
    "        else:\n",
    "            return 'no'\n",
    "    #else return no\n",
    "    else:\n",
    "        return 'no'\n",
    "#apply the function and store the new value in the column city\n",
    "df_tweets['city'] = df_tweets.apply(lambda row: city(row['location1']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-6382041f244f>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  use['state'] = use.apply(lambda row: state(row['location2']),axis=1)\n"
     ]
    }
   ],
   "source": [
    "#after creating that designated None value we can now create a function to find the state name if there is one\n",
    "def state(place):\n",
    "    #if there is some information about the place continue\n",
    "    if type(place) != none:\n",
    "        #if there is state return the state value\n",
    "        if place[1].state != '':\n",
    "            return place[1].state\n",
    "        #else return no\n",
    "        else:\n",
    "            return 'no'\n",
    "    #else return no\n",
    "    else:\n",
    "        return 'no'\n",
    "#apply the function and store the new value in the column state\n",
    "use['state'] = use.apply(lambda row: state(row['location1']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   12,   159,  4896,  5105,  5641,  5642,  5719,  5724,  5725,\n",
       "             5726,\n",
       "            ...\n",
       "            18581, 18582, 18583, 18584, 18585, 18586, 18587, 18588, 18589,\n",
       "            18590],\n",
       "           dtype='int64', length=3305)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we look at the tweets that Carmen didn't pick up because they were stored in the user created location\n",
    "#and get their index\n",
    "where = df_tweets[(use['user-location'] != '') & (use['city'] == 'no')]['user-location'].index\n",
    "where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "#now we sort through those indexes where there were user locations and store them in the city and state values\n",
    "#that we made earlier\n",
    "for x in where:\n",
    "    #get the data from user location\n",
    "    place = use.loc[x]['user-location']\n",
    "    #if there multiple values in the user-location separate these values\n",
    "    if ',' in place:\n",
    "        #split the values\n",
    "        s = place.split(',')\n",
    "        #check the lenght of the list\n",
    "        if len(s) == 2:\n",
    "            #if it's two check if the second one is the US, if it's not then it's a state and city value\n",
    "            if s[1] != ' US' or 'US':\n",
    "                #assign the values \n",
    "                city = s[0]\n",
    "                state = s[1]\n",
    "                #check the values for ones that we know are already messed up\n",
    "                if use.loc[x, 'city'] == 'Orange County' or \"San Gabriel Valley\":\n",
    "                    use.loc[x,'city'] = 'Los Angeles'\n",
    "                    use.loc[x,'state'] = 'California'\n",
    "                if use.loc[x,'city'] == 'Sonoma County':\n",
    "                    use.loc[x,'city'] = 'San Francisco'\n",
    "                    use.loc[x,'state'] = 'California'\n",
    "                #check the first value of city to see if there is a space, if there is one take the space out\n",
    "                else:\n",
    "                    if city[1] == ' ':\n",
    "                        use.loc[x,'city'] = city[1:]\n",
    "                    if state[1] == ' ':\n",
    "                        use.loc[x,'state'] = state[1:]\n",
    "                    else:\n",
    "                        use.loc[x,'city'] = city\n",
    "                        use.loc[x,'state'] = state\n",
    "            elif s[1] == ' US' or 'US':\n",
    "                state = s[0]\n",
    "                use.loc[x,'state'] = state\n",
    "    else:\n",
    "        if place == 'DC via Nigeria':\n",
    "            use.loc[x,'city'] = 'D.C.'\n",
    "            use.loc[x,'state'] = 'D.C.'\n",
    "        if place == 'City of Brotherly Love':\n",
    "            use.loc[x,'city'] = 'Philadelphia'\n",
    "            use.loc[x,'state'] = 'Pennsylvania'\n",
    "        if place == 'SOUTH PHILADELPHIA—':\n",
    "            use.loc[x,'city'] = 'Philadelphia'\n",
    "            use.loc[x,'state'] = 'Pennsylvania'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
